# 產品需求文件 (PRD): 現代化 RAG 查詢平台

**文件版本:** 1.0
**日期:** 2025年8月5日

---

## 第一章：目標與背景 (Goals and Background Context)

### 1.1 目標 (Goals)
* 為企業提供一個統一、智慧化的內部資料查詢入口。
* 將特定問題的資訊檢索時間從數小時大幅縮短至數分鐘內。
* 透過提供可追溯來源的答案，提升決策的準確性與信賴度。

### 1.2 背景 (Background Context)
在目前的作業流程中，企業內部關鍵資料（如歷史報價、採購紀錄）散落在多個獨立的系統與文件格式中。員工需耗費大量時間手動查找與比對，過程不僅效率低落，也存在使用過時或不完整資訊的風險。本專案旨在解決此痛點，建立一個一站式的智慧查詢平台。

### 1.3 變更日誌 (Change Log)
| 日期 | 版本 | 描述 | 作者 |
| --- | --- | --- | --- |
| 2025年8月5日 | 1.0 | 初始草稿 | John (PM) |

---

## 第二章：功能需求 (Requirements)

### 2.1 功能性需求 (Functional Requirements)
* **FR1**: 系統必須提供使用者註冊與登入功能。
* **FR2**: 系統必須支援一次上傳多個檔案（如 PDF, TXT, CSV）。
* **FR3**: 系統必須在一個主畫面上，以卡片形式顯示所有已上傳的資料集。
* **FR4**: 使用者必須能透過一個 Chatbot 介面，使用自然語言進行提問。
* **FR5**: Chatbot 介面必須顯示使用者的歷史對話紀錄。
* **FR6**: 介面必須提供可點擊的「問題範本」按鈕以引導使用者。
* **FR7**: 點擊「問題範本」按鈕後，必須將對應的文字格式填入對話輸入框中，供使用者編輯。
* **FR8**: Chatbot 的所有回答都必須附上其資訊來源。
* **FR9**: 資訊來源必須以可「收合/展開」的內容預覽片段形式呈現。

### 2.2 非功能性需求 (Non-Functional Requirements)
* **NFR1**: 系統的使用者介面必須是簡潔、專業的商務風格，避免使用過於絢麗的色彩。
* **NFR2**: 系統的後端必須使用 `autogen` 框架作為多代理協作的核心。
* **NFR3**: 系統必須能夠整合外部大型語言模型 (LLM) 的 API，例如 Google Gemini 或 Anthropic Claude。
* **NFR4**: 對於典型的查詢，系統的回應時間應在15秒內，以確保良好的使用者體驗。

---

## 第三章：使用者介面設計目標 (User Interface Design Goals)

### 3.1 整體 UX 願景 (Overall UX Vision)
整體 UX 願景是打造一個直觀、高效且值得信賴的資訊查詢工具。介面應保持簡潔，讓使用者能專注於「提問」與「獲取答案」的核心任務上，避免不必要的干擾。

### 3.2 關鍵互動模式 (Key Interaction Paradigms)
主要的互動模式為「對話式介面」。所有查詢都透過與 Chatbot 的問答來完成。輔助性的互動包含「拖曳上傳」檔案與「點擊卡片」管理資料集。

### 3.3 核心畫面 (Core Screens and Views)
從產品角度，MVP 階段交付價值所需的最關鍵畫面包括：
* 登入/註冊頁面
* 主儀表板 (包含資料集卡片列表與 Chatbot 介面)
* 使用者設定檔頁面

### 3.4 無障礙設計 (Accessibility)
MVP 階段將以 WCAG AA 級別為目標，確保介面對於所有使用者都具有良好的可用性，例如足夠的色彩對比、鍵盤導航支援等。

### 3.5 品牌風格 (Branding)
遵循使用者先前指定的「簡潔、商務風格」，色彩將以中性色調（如灰、藍）為主，搭配單一的強調色，以建立專業、穩重的視覺感受。

### 3.6 目標平台 (Target Device and Platforms)
目標平台為「響應式網頁 (Web Responsive)」，確保在桌面瀏覽器上有最佳體驗，並在平板和手機上有可用的介面。

---

## 第四章：技術假設 (Technical Assumptions)

### 4.1 儲存庫結構 (Repository Structure): Monorepo
* **建議說明:** 將前端、後端 (`autogen` 服務) 和共享的程式碼（例如，API 的資料類型定義）都放在同一個 Git 儲存庫中。
* **理由:** 對於一個新的全端專案，Monorepo 能簡化依賴管理、促進程式碼共享，並統一 CI/CD 流程，有助於 MVP 階段的快速迭代。

### 4.2 服務架構 (Service Architecture): Serverless (無伺服器架構)
* **建議說明:** 核心的後端查詢服務將部署為無伺服器函數（例如 AWS Lambda 或 Google Cloud Functions）。
* **理由:** RAG 平台的查詢本質是事件驅動的（收到請求 -> 執行 -> 回傳結果），非常適合無伺服器架構。這在 MVP 階段具有極高的成本效益（按使用量付費），且能自動擴展，無需管理伺服器。

### 4.3 測試需求 (Testing Requirements): Unit + Integration (單元測試 + 整合測試)
* **建議說明:** 開發階段必須包含單元測試（測試獨立的函數或元件）和整合測試（測試關鍵的端到端流程，如 API 接收請求到 RAG 回傳結果）。
* **理由:** 這是 MVP 階段最務實的作法，能在確保核心功能品質的同時，不過度增加開發時間。完整的端到端 (E2E) 測試可在後續版本中擴充。

### 4.4 其他技術假設 (Additional Technical Assumptions)
* 在後續的討論中，若有其他技術決策，將會補充於此。

---

## 第五章：史詩列表 (Epic List)

* **Epic 1: 專案基礎與使用者認證 (Foundation & User Authentication)**
    * **目標:** 建立專案基礎設施、部署管線與核心使用者認證功能，為後續功能提供穩固基礎。
* **Epic 2: 核心 RAG 管道與資料注入 (Core RAG Pipeline & Data Ingestion)**
    * **目標:** 實現核心資料上傳與管理功能，讓使用者能將其資料集匯入平台並進行檢視。
* **Epic 3: 基礎 RAG 對話機器人 (Basic RAG Chatbot)**
    * **目標:** 實現一個**單一代理**的 RAG 查詢功能，驗證從前端提問到後端從單一資料來源檢索並回傳附來源答案的核心流程。
* **Epic 4: Multi-Agent 框架整合 (Multi-Agent Framework Integration)**
    * **目標:** 在基礎 RAG 之上，導入 `autogen` **多代理框架**，讓系統能夠管理多個專門的 AI 代理，並根據問題智慧地進行任務路由，提升回答的精準度與廣度。

---

## 第六章：Epic 詳細內容

### Epic 1: 專案基礎與使用者認證
**擴展目標:** 本 Epic 的核心目標是搭建一個穩固、可擴展的專案骨架。我們將從建立 Monorepo 儲存庫開始，設定開發標準與 CI/CD 基礎管線。隨後，我們將實現一個完整的、端到端的使用者認證流程，包括後端 API 和前端登入頁面。完成此 Epic 後，我們將擁有一個可以實際部署、註冊、登入並保護路由的最小化應用程式。

* **Story 1.1: 專案初始化與 Monorepo 結構設定**
    * As a 開發者, I want 一個配置好的 Monorepo 儲存庫結構, so that 我可以從專案一開始就確保一致的開發標準與環境。
    * **驗收標準:** 1. 使用 `npm workspaces` 或 `Turborepo` 初始化 Monorepo。 2. `apps` 資料夾內建立 `frontend` 和 `backend` 兩個應用程式目錄。 3. `packages` 資料夾內建立 `eslint-config-custom` 和 `tsconfig` 用於共享配置。 4. 根目錄建立 `README.md` 和基本的 Git 版控設定。
* **Story 1.2: 使用者模型與資料庫設定**
    * As a 系統, I want 一個基礎的使用者資料模型與資料庫連接, so that 使用者資訊可以被安全地儲存與讀取。
    * **驗收標準:** 1. 定義使用者 (User) 的資料庫綱要 (Schema)，至少包含 `email`, `password_hash`。 2. 後端應用程式能成功連接到指定的資料庫。 3. 建立一個資料庫遷移 (migration) 腳本，用於生成 `users` 資料表。
* **Story 1.3: 使用者註冊 API 端點**
    * As a 新使用者, I want 透過 API 註冊一個新帳號, so that 我可以開始使用這個平台。
    * **驗收標準:** 1. 建立 `POST /api/auth/register` 端點。 2. 端點能接收 `email` 和 `password`。 3. 密碼在存入資料庫前必須經過雜湊 (hashing) 處理。 4. 成功註冊後，回傳成功的訊息；若使用者已存在，則回傳錯誤訊息。
* **Story 1.4: 使用者登入 API 端點與 JWT 簽發**
    * As a 已註冊使用者, I want 透過 API 登入系統, so that 我能取得一個驗證權杖 (token) 以存取安全資源。
    * **驗收標準:** 1. 建立 `POST /api/auth/login` 端點。 2. 端點能驗證 `email` 和 `password` 是否正確。 3. 驗證成功後，簽發一個包含使用者資訊的 JWT (JSON Web Token) 並回傳給客戶端。 4. 驗證失敗，則回傳錯誤訊息。
* **Story 1.5: 基礎前端登入/註冊頁面**
    * As a 訪客, I want 一個簡單的登入與註冊頁面, so that 我可以登入或建立我的帳號。
    * **驗收標準:** 1. 前端應用程式建立 `/login` 路由與對應頁面。 2. 頁面包含 `email` 和 `password` 輸入框，以及「登入」和「註冊」按鈕。 3. 點擊按鈕能觸發對應的 API 請求。 4. 登入成功後，收到的 JWT 必須被儲存在瀏覽器中。 5. 登入成功後，頁面跳轉至主儀表板。
* **Story 1.6: 前後端路由保護**
    * As a 已登入使用者, I want 能夠存取受保護的頁面，而未登入者不能, so that 我知道我的帳號是安全的。
    * **驗收標準:** 1. 前端建立一個受保護的路由（例如 `/dashboard`）。 2. 未登入的使用者訪問 `/dashboard` 時，會被自動導向 `/login` 頁面。 3. 後端建立一個受保護的 API 端點，只有在請求標頭附帶有效 JWT 時才能成功訪問。

### Epic 2: 核心 RAG 管道與資料注入
**擴展目標:** 本 Epic 的目標是實現一個完整的、從前端到後端的資料注入與處理管道。完成後，使用者將能夠建立自己的資料集、上傳多個檔案，並在儀表板上看到這些資料集的處理狀態。後端將具備將文件轉換為可供 AI 檢索的向量化資料的能力，為 Epic 3 的智慧問答功能奠定資料基礎。

* **Story 2.1: 資料集與檔案的資料庫模型**
    * As a 系統, I want 一個能追蹤資料集與其對應檔案的資料庫模型, so that 我能管理每個使用者上傳的資料集合及其處理狀態。
    * **驗收標準:** 1. 建立 `Dataset` 資料庫綱要，至少包含 `id`, `name`, `owner_id`。 2. 建立 `File` 資料庫綱要，至少包含 `id`, `filename`, `status`，並與 `Dataset` 關聯。 3. 建立對應的資料庫遷移腳本。
* **Story 2.2: 安全的檔案上傳 API 端點**
    * As a 已登入使用者, I want 一個安全的 API 端點來上傳我的資料檔案, so that 檔案能被系統接收並儲存以進行後續處理。
    * **驗收標準:** 1. 建立一個受路由保護的 `POST /api/datasets/:datasetId/files` 端點。 2. 此端點支援多檔案同時上傳。 3. 上傳的檔案被安全地儲存在指定的暫存位置。 4. 每筆檔案的元數據需記錄到 `File` 資料表中，初始狀態為 `pending`。
* **Story 2.3: 前端資料集建立與檔案上傳介面**
    * As a 已登入使用者, I want 一個簡單的介面來建立新資料集並上傳檔案, so that 我可以開始資料注入的流程。
    * **驗收標準:** 1. 儀表板頁面提供一個「建立新資料集」的按鈕。 2. 使用者可以為新資料集命名，並選擇多個檔案進行上傳。 3. 介面需要顯示每個檔案的上傳進度。 4. 上傳成功後，呼叫 Story 2.2 的 API 端點。
* **Story 2.4: 非同步文件處理與向量化管線**
    * As a 系統, I want 一個非同步的背景處理管線來處理上傳完的檔案, so that 我能將文件內容轉換為可供 AI 檢索的向量嵌入。
    * **驗收標準:** 1. 檔案上傳成功後，自動觸發一個背景作業。 2. 背景作業能讀取指定檔案的內容。 3. 檔案內容被分割為較小的文字區塊。 4. 文字區塊需透過呼叫位於 `http://ollama.webtw.xyz:11434` 的 Ollama服務，使用 `all-minilm:l6-v2` 模型轉換為向量嵌入。 5. 轉換後的向量嵌入與原始文本一同儲存至向量資料庫。 6. 處理完成後，`File` 資料表中的狀態從 `pending` 更新為 `ready`。
* **Story 2.5: 在儀表板上顯示資料集列表**
    * As a 已登入使用者, I want 在儀表板上看到我所有資料集的列表與狀態, so that 我能管理我的資料並了解它們是否已準備好被查詢。
    * **驗收標準:** 1. 建立 `GET /api/datasets` 端點，用以獲取目前使用者的所有資料集。 2. 前端儀表板呼叫此 API。 3. 每個資料集以「卡片」形式呈現，至少顯示其名稱與整體處理狀態。

### Epic 3: 基礎 RAG 對話機器人
**擴展目標:** 本 Epic 的目標是交付一個功能性的、端到端的 RAG 問答迴圈。使用者將能夠在介面上提問，後端系統會執行一次基本的「單一代理」RAG 流程，最終將附有來源的答案呈現給使用者。這是整個平台首次展現核心價值的時刻。

* **Story 3.1: 後端查詢 API 端點**
    * As a 開發者, I want 一個安全的 API 端點來接收使用者的查詢, so that 我可以觸發後續的 RAG 處理流程。
    * **驗收標準:** 1. 建立一個受路由保護的 `POST /api/chat` 端點。 2. 此端點至少能接收 `query` 和 `datasetId` 兩個參數。 3. 對傳入的參數進行基本驗證。
* **Story 3.2: 基礎 RAG 檢索邏輯 (Retrieval)**
    * As a 系統, I want 將收到的查詢轉換為向量，並從向量資料庫中尋找最相關的文字區塊, so that 我能為語言模型準備好生成答案所需的上下文。
    * **驗收標準:** 1. 使用者的 `query` 透過指定的 Ollama 模型轉換為向量嵌入。 2. 系統根據 `datasetId` 在向量資料庫中執行相似性搜尋。 3. 成功檢索到最相關的前 N 筆文字區塊。 4. 需處理檢索不到任何相關內容的例外情況。
* **Story 3.3: LLM 提示詞工程與答案生成 (Generation)**
    * As a 系統, I want 將使用者問題和檢索到的上下文組合成一個有效的提示詞，並交由 LLM 生成答案, so that 我能產出一個精準且有根據的回答。
    * **驗收標準:** 1. 建立一個提示詞模板。 2. 系統向外部 LLM 發起 API 呼叫。 3. 成功接收 LLM 生成的回答。 4. 將生成的回答與其對應的來源資訊一同回傳。
* **Story 3.4: 前端 Chatbot 互動介面**
    * As a 已登入使用者, I want 一個可以輸入問題並看到完整對話歷史的聊天介面, so that 我可以與我的資料進行互動。
    * **驗收標準:** 1. 主儀表板頁面包含一個聊天視窗。 2. 聊天視窗有對話輸入框與「傳送」按鈕。 3. 使用者的對話歷史紀錄會顯示在主視窗區域。 4. 「問題範本」按鈕功能正常。
* **Story 3.5: 在前端呈現附有來源的回答**
    * As a 使用者, I want 在收到 Chatbot 回答時，能清楚看到資訊的來源, so that 我可以驗證答案的準確性。
    * **驗收標準:** 1. 使用者送出問題後，前端呼叫 `POST /api/chat`。 2. 在等待時，介面需顯示載入中提示。 3. 成功後，LLM 的答案會顯示在聊天視窗中。 4. 答案下方以可「收合/展開」的 UI 元件，顯示來源內容預覽。 5. 若 API 回傳錯誤，介面需能顯示錯誤訊息。

### Epic 4: Multi-Agent 框架整合
**擴展目標:** 本 Epic 的目標是在現有 RAG 功能之上，成功導入並整合 `autogen` 多代理框架。完成後，系統將擁有「指揮官」與「專家」的協作能力，為產品的未來智慧升級鋪平了道路。

* **Story 4.1: `autogen` 代理管理器 (Agent Manager)**
    * As a 開發者, I want 一個中央化的代理管理器服務, so that 我可以在 `autogen` 框架中，方便地定義、註冊與配置各種專門的 AI 代理。
    * **驗收標準:** 1. 建立一個後端服務，用以管理 AI 代理的配置。 2. 將 Epic 3 的 RAG 檢索邏輯，封裝成一個可供代理使用的「工具」。 3. 在管理器中註冊兩個專家代理：「文件查詢代理」和「結構化資料代理 (ERP 原型)」。
* **Story 4.2: 查詢路由器 / 協調員代理**
    * As a 系統, I want 一個頂層的「協調員」代理來分析使用者問題，並將任務指派給最合適的專家代理, so that 正確的工具能被用來解決正確的問題。
    * **驗收標準:** 1. 在 `autogen` 中實作一個「協調員」代理。 2. `POST /api/chat` 端點現在將查詢傳送給「協調員」。 3. 「協調員」代理能根據問題的語意，判斷應將任務指派給哪個專家代理。
* **Story 4.3: 代理間的任務交接與成果回報**
    * As a 系統, I want 一個標準化的通訊協定，讓協調員與專家代理能順暢地交接任務與回報成果, so that 整個多代理協作流程能夠穩定運行。
    * **驗收標準:** 1. 「協調員」能成功地將任務傳遞給指定的專家代理。 2. 專家代理能成功執行其工具。 3. 專家代理將其結果回報給「協調員」。 4. 「協調員」將結果整理後回傳給 API。
* **Story 4.5: 建立結構化資料代理 (ERP 原型)**
    * As a 開發者, I want 建立一個模擬的「結構化資料代理」，它會回傳預先定義好的 JSON 假資料, so that 我可以完整地測試「協調員」代理的任務指派與路由功能。
    * **驗收標準:** 1. 「結構化資料代理」被成功建立並註冊。 2. 此代理的「工具」被呼叫時，回傳一份預先定義好的、固定格式的 JSON 內容。 3. 「協調員」代理知道這位新專家的存在及其能力。

---

## 第七章：檢查清單結果報告 (Checklist Results Report)
PM 需求清單 (`pm-checklist`) 驗證完畢。報告顯示，本 PRD 內容完整、史詩劃分清晰、需求明確，符合高品質標準，已準備好進入下一個階段。

---

## 第八章：下一步 (Next Steps)
本 PRD 文件完成後，專案將進入設計與架構階段。以下是交接給下一階段專家的指示：

### 8.1 給 UX 專家 (UX Expert) 的指示
> 這份 PRD 已經定義了「現代化 RAG 查詢平台」的核心需求與 MVP 範圍。請您（UX 專家）根據第三章的 UI/UX 設計目標和功能需求，建立一份詳細的「UI/UX 規格文件 (front-end-spec.md)」，包含使用者流程、線框圖 (wireframes) 和元件設計等。

### 8.2 給架構師 (Architect) 的指示
> 這份 PRD 已經定義了「現代化 RAG 查詢平台」的核心需求與 MVP 範圍。請您（架構師）根據第四章的技術假設和所有功能需求，設計一份完整的「全端架構文件 (fullstack-architecture.md)」，確保系統的穩健性、擴展性和安全性。